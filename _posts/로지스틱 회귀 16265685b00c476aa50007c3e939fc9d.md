# ë¡œì§€ìŠ¤í‹± íšŒê·€

# Logistic Regression

## ì´ë¡ 

ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ì„ í˜• íšŒê·€ì²˜ëŸ¼ ì¢…ì† ë³€ìˆ˜ì™€ ë…ë¦½ ë³€ìˆ˜ê°„ì˜ ê´€ê³„ë¥¼ ì„±ë¦½í•˜ì—¬ íŠ¹ì • ë°ì´í„°ì˜ ê°’ì„ ì˜ˆì¸¡í•œë‹¤. í•˜ì§€ë§Œ ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ì„ í˜• íšŒê·€ì™€ ë‹¤ë¥´ê²Œ ì¼ì • ë²”ìœ„ ë‚´ì—ì„œ ì¶”ë¡ í•´ë‚´ê³  íŠ¹ì • ë°ì´í„°ê°€ ì…ë ¥ë˜ì—ˆë‹¤ë©´ ê·¸ ë°ì´í„°ê°€ ì–´ëŠ ë¶„ë¥˜ì— ì†í•˜ëŠ”ì§€ë¥¼ ë°˜í™˜í•˜ê¸° ë•Œë¬¸ì— ì¼ì¢…ì˜ ë¶„ë¥˜(Classification) ê¸°ë²•ì´ë¼ê³  í•  ìˆ˜ ìˆë‹¤. ë‹¤ìŒì€ ìœ„í‚¤ë°±ê³¼ì˜ ë‚´ìš©ì´ë‹¤ : 

<aside>
ğŸ“Œ ë¡œì§€ìŠ¤í‹± íšŒê·€ì˜ ëª©ì ì€ ì¼ë°˜ì ì¸Â [**íšŒê·€ ë¶„ì„**](https://ko.wikipedia.org/wiki/%ED%9A%8C%EA%B7%80_%EB%B6%84%EC%84%9D)ì˜ ëª©í‘œì™€ ë™ì¼í•˜ê²ŒÂ **[ì¢…ì† ë³€ìˆ˜](https://ko.wikipedia.org/wiki/%EB%8F%85%EB%A6%BD_%EB%B3%80%EC%88%98%EC%99%80_%EC%A2%85%EC%86%8D_%EB%B3%80%EC%88%98)**ì™€ ë…ë¦½ ë³€ìˆ˜ê°„ì˜ ê´€ê³„ë¥¼ êµ¬ì²´ì ì¸ í•¨ìˆ˜ë¡œ ë‚˜íƒ€ë‚´ì–´ í–¥í›„ ì˜ˆì¸¡ ëª¨ë¸ì— ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. ì´ëŠ” ë…ë¦½ ë³€ìˆ˜ì˜ ì„ í˜• ê²°í•©ìœ¼ë¡œ **ì¢…ì† ë³€ìˆ˜**ë¥¼ ì„¤ëª…í•œë‹¤ëŠ” ê´€ì ì—ì„œëŠ”Â [ì„ í˜• íšŒê·€](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80)Â ë¶„ì„ê³¼ ìœ ì‚¬í•˜ë‹¤. í•˜ì§€ë§Œ ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ”Â [ì„ í˜• íšŒê·€](https://ko.wikipedia.org/wiki/%EC%84%A0%ED%98%95_%ED%9A%8C%EA%B7%80)Â ë¶„ì„ê³¼ëŠ” ë‹¤ë¥´ê²Œ ì¢…ì† ë³€ìˆ˜ê°€ ë²”ì£¼í˜• ë°ì´í„°ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•˜ë©° ì…ë ¥ ë°ì´í„°ê°€ ì£¼ì–´ì¡Œì„ ë•Œ í•´ë‹¹ ë°ì´í„°ì˜ ê²°ê³¼ê°€ íŠ¹ì • ë¶„ë¥˜ë¡œ ë‚˜ë‰˜ê¸° ë•Œë¬¸ì— ì¼ì¢…ì˜ **ë¶„ë¥˜([classification](https://en.wikipedia.org/wiki/classification)) ê¸°ë²•**ìœ¼ë¡œë„ ë³¼ ìˆ˜ ìˆë‹¤.

</aside>

ì–´ë–¤ ë°ì´í„°ê°€ ì£¼ì–´ì¡Œì„ë•Œ, ê·¸ ë°ì´í„°ê°€ ë¶„ë¥˜ A, ë¶„ë¥˜ B, ë¶„ë¥˜ C ....ì˜ í™•ë¥ ì„ êµ¬í•˜ëŠ” ê²ƒì´ë‹¤.

K-NN íšŒê·€ë¥¼ ì´ìš©í•´ì„œ êµ¬í• ìˆ˜ë„ ìˆê³ , ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì´ìš©í•´ì„œ êµ¬í•  ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ K-NNíšŒê·€ëŠ” ìµœê·¼ì ‘ ì´ì›ƒì˜ ê°œìˆ˜(n-neighbors)ë¥¼ ë¶„ëª¨ë¡œ í•˜ì—¬ í™•ë¥ ì„ ê³„ì‚°í•œë‹¤. ë•Œë¬¸ì— ëª¨ë¸ë§ˆë‹¤ ë‹¤ë¥¸ í™•ë¥ ì´ ë‚˜ì˜¬ ìˆ˜ ìˆê³  ë¶€ì •í™•í•˜ë‹¤.

í•˜ì§€ë§Œ ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ë‹¤í•­ íšŒê·€ì™€ ê°™ì´ ê³„ìˆ˜ì™€ ì ˆí¸ì„ êµ¬í•´ ì•Œë§ì€ ë°©ì •ì‹ì„ ì„¸ìš°ê³  ê·¸ ë°©ì •ì‹ì„ í†µê³¼í•´ ê° ë°ì´í„°ë“¤ì„ ë°©ì •ì‹ì— ëŒ€ì…í–ˆì„ ë•Œ ë‚˜ì˜¤ëŠ” ê°’ zì„ **ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ í˜¹ì€ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜**ì— í†µê³¼ì‹œì¼œ í™•ë¥ ì„ ë„ì¶œí•´ ë‚¸ë‹¤.

---

ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë€ zê°’ì— ë”°ë¼ 0ê³¼ 1ì‚¬ì´ì˜ ê²°ê³¼ê°’(Î¦)ë¥¼ ë°˜í™˜í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤. zê°’ì´ ì‘ì„ìˆ˜ë¡ Î¦ëŠ” 0ì— ìˆ˜ë ´í•˜ê³ , zê°’ì´ í´ìˆ˜ë¡ Î¦ëŠ” 1ì— ìˆ˜ë ´í•˜ëŠ” ë‹¤ìŒê³¼ ê°™ì€ í•¨ìˆ˜ì´ë‹¤.

![Untitled](%E1%84%85%E1%85%A9%E1%84%8C%E1%85%B5%E1%84%89%E1%85%B3%E1%84%90%E1%85%B5%E1%86%A8%20%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%2016265685b00c476aa50007c3e939fc9d/Untitled.png)

ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì˜ ì‹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.

$$
â
$$

---

### ì½”ë“œ

**K-NN íšŒê·€**

```python
from sklearn.neighbors import KNeighborsClassifier
kn = KNeighborsClassifier(n_neighbors = 3)
kn.fit(train_scaled, train_target)
print('\n Train & Test score : ')
print("train_scaled : " + str(kn.score(train_scaled, train_target)))
print("test_scaled : " + str(kn.score(test_scaled, test_target)))

print('\n KN Classes : ')
print(kn.classes_)
```

![Untitled](%E1%84%85%E1%85%A9%E1%84%8C%E1%85%B5%E1%84%89%E1%85%B3%E1%84%90%E1%85%B5%E1%86%A8%20%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%2016265685b00c476aa50007c3e939fc9d/Untitled%201.png)

kn.classes_ ì—ëŠ” ë°ì´í„°ë“¤ì˜ íŠ¹ì„±ì´ ë‹´ê²¨ìˆë‹¤.

í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ì²˜ìŒ ë‹¤ì„¯ ê°œ ìƒ˜í”Œë“¤ì„ ê°€ì ¸ì™€ ì˜ˆì¸¡í•´ë³´ì.

K-NNíšŒê·€ì˜ predict()í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤.

ë˜ predict_proba()í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ë©´ ê° ì˜ˆì¸¡ ê²°ê³¼ì˜ í™•ë¥ ì„ ì–»ì„ ìˆ˜ ìˆë‹¤.

```python
# ì²˜ìŒ 5ê°œì˜ ìƒ˜í”Œ íƒ€ê¹ƒ ì¶œë ¥
print('\n 5 predicts of test_scaled : ')
print(kn.predict(test_scaled[:5]))
# ['Perch' 'Smelt' 'Pike' 'Perch' 'Perch'] ë¡œ ì˜ˆì¸¡ì¤‘. í™•ë¥ ì„ êµ¬í•´ë³´ì

# ê°ê°ì˜ í™•ë¥  ì¶œë ¥
import numpy as np
proba = kn.predict_proba(test_scaled[:5])
print('\n Each probablity : ')
print(np.round(proba, decimals = 4))
```

![Untitled](%E1%84%85%E1%85%A9%E1%84%8C%E1%85%B5%E1%84%89%E1%85%B3%E1%84%90%E1%85%B5%E1%86%A8%20%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%2016265685b00c476aa50007c3e939fc9d/Untitled%202.png)

ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë³´ë©´ 1/3, 2/3, 3/3 ìœ¼ë¡œ ë¶„ëª¨ê°€ 3ì¸ ë¶„ìˆ˜ë¡œë§Œ ì´ë£¨ì–´ì ¸ ìˆë‹¤. ì´ëŠ” K-NN íšŒê·€ ëª¨ë¸ì˜ n_neighbors (nê°œì˜ ìµœê·¼ì ‘ ì´ì›ƒ)ì´ 3ìœ¼ë¡œ ì •í•´ì ¸ ìˆê¸° ë•Œë¬¸ì´ë‹¤.

---

**ë¡œì§€ìŠ¤í‹± íšŒê·€ (Logistic Regression)**

ë¡œì§€ìŠ¤í‹± íšŒê·€ë¥¼ ì´ìš©í•´ë³´ì.

---

ë¨¼ì € **ì´ì§„ë¶„ë¥˜**. ì •ë‹µì€ ì–‘ì„± í´ë˜ìŠ¤ (1) ê³¼ ìŒì„± í´ë˜ìŠ¤(0)ë§Œ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì´ë‹¤.

```python
bream_smelt_indexes = (train_target == "Bream") | (train_target == "Smelt")
train_bream_smelt = train_scaled[bream_smelt_indexes]
target_bream_smelt = train_target[bream_smelt_indexes]

# ë¡œì§€ìŠ¤í‹± íšŒê·€ (Logistic Regression)ì„ ì´ìš©í•´ í•™ìŠµí•˜ê³  í™•ë¥ ì„ êµ¬í•  ê²ƒ.
# í•™ìŠµí•˜ëŠ” ë°©ë²• : 1. ì˜ˆì¸¡ì„ í•´ì„œ(fit) ë°©ì •ì‹ì˜ ê³„ìˆ˜(coefficient)ë¥¼ ì •ì˜í•œë‹¤.
from sklearn.linear_model import LogisticRegression
lr = LogisticRegression()
lr.fit(train_bream_smelt, target_bream_smelt)
```

ì—¬ê¸°ì„œ ë°”ë¡œ lr.predict()ì™€ lr.predict_proba()ë¥¼ ì´ìš©í•´ í™•ë¥ ì„ êµ¬í•  ìˆ˜ ìˆë‹¤.

```python
print("lr predict , predict_proba : ")
print(lr.predict(train_bream_smelt[:5]))
print(lr.predict_proba(train_bream_smelt[:5]))
```

![Untitled](%E1%84%85%E1%85%A9%E1%84%8C%E1%85%B5%E1%84%89%E1%85%B3%E1%84%90%E1%85%B5%E1%86%A8%20%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%2016265685b00c476aa50007c3e939fc9d/Untitled%203.png)

í•˜ì§€ë§Œ ê³„ìˆ˜ë¥¼ ì§ì ‘ êµ¬í•´ì„œ zê°’ì„ êµ¬í•œ í›„ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì— ë„£ì–´ ê²°ê³¼ê°’ì„ ë„ì¶œí•´ ë³¼ ìˆ˜ë„ ìˆë‹¤.

```python
print("\nCoefficients of Logistic Regression for Binary Classification :")
print("coef : " + str(lr.coef_))
print("intercept : " + str(lr.intercept_))

decisions = lr.decision_function(train_bream_smelt[:5])
print("Z(decisions) : " + str(decisions))
```

![Untitled](%E1%84%85%E1%85%A9%E1%84%8C%E1%85%B5%E1%84%89%E1%85%B3%E1%84%90%E1%85%B5%E1%86%A8%20%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%2016265685b00c476aa50007c3e939fc9d/Untitled%204.png)

ì´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ ì‹ì´ ì„±ë¦½í•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤.

$$
z = -0.404 * (íŠ¹ì„±1) -0.576 * (íŠ¹ì„±2) -0.663 * (íŠ¹ì„±3) -1.013 * (íŠ¹ì„±4) - 0.732 * (íŠ¹ì„±5) -2.162
$$

ê·¸ë¦¬ê³  Z(decisions) ëŠ” train_bream_smeltì˜ 0ë²ˆì§¸ ë¶€í„° 4ë²ˆì§¸ ê¹Œì§€ì˜ ìƒ˜í”Œë“¤ì„ ìœ„ ë°©ì •ì‹ì— ë„£ì—ˆì„ ë•Œ ë‚˜ì˜¤ëŠ” ê°’ì´ë‹¤.

ì´ì œ ì´ zë¥¼ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì— ë„£ì–´ í™•ë¥ ì„ êµ¬í•´ë³´ì.

```python
from scipy.special import expit
print("\nResult of sigmoid function with decisions by expit function")
print(expit(decisions))
```

![Untitled](%E1%84%85%E1%85%A9%E1%84%8C%E1%85%B5%E1%84%89%E1%85%B3%E1%84%90%E1%85%B5%E1%86%A8%20%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%2016265685b00c476aa50007c3e939fc9d/Untitled%205.png)

ê·¸ ê²°ê³¼ëŠ” ìœ„ lr.predict_proba()ì˜ 2ì—´ ë‚´ìš©ê³¼ ê°™ìŒì„ ì•Œ ìˆ˜ ìˆë‹¤.

**LogisticRegression**ì˜ predict_proba() ë©”ì„œë“œëŠ” ìŒì„±/ì–‘ì„± í´ë˜ìŠ¤ì˜ í™•ë¥ ì„ ëª¨ë‘ ë³´ì—¬ì£¼ê³ , zê°’ì„ ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ì— ë„£ì–´ ë‚˜ì˜¨ ê°’ì€ ì–‘ì„± í´ë˜ìŠ¤ì˜ í™•ë¥  ê°’ë§Œ ë„ì¶œí•œë‹¤.

---

**ë‹¤ì¤‘ë¶„ë¥˜**

ë‹¤ì¤‘ë¶„ë¥˜ëŠ” ì´ì§„ë¶„ë¥˜ì™€ í° ì°¨ì´ê°€ ì—†ë‹¤. ë‹¤ë§Œ, ì‹œê·¸ëª¨ì´ë“œ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•´ decisionsê°’ì„ 0~1ì‚¬ì´ì˜ ê°’ìœ¼ë¡œ ë³€í™˜í•œë‹¤.

```python
lr2 = LogisticRegression(C=20, max_iter=1000) 
# CëŠ” 1/alpha ì¦‰ Cê°€ ì‘ì„ìˆ˜ë¡ ê·œì œê°€ í¼, max_iterëŠ” ì¶©ë¶„íˆ í›ˆë ¨ì‹œí‚¤ê¸° ìœ„í•œ ë°˜ë³µíšŸìˆ˜
lr2.fit(train_scaled, train_target)
print("\nTrain & Test score")
print("Train Score : " +  str(lr2.score(train_scaled, train_target)))
print("Test Score : " + str(lr2.score(test_scaled, test_target)))

# ì ìˆ˜ê°€ ê´œì°®ìœ¼ë‹ˆ ì²˜ìŒ 5ê°œ ìƒ˜í”Œì— ëŒ€í•œ ì˜ˆì¸¡
print("\n Predict for 5 test_scaled")
print(lr2.predict(test_scaled[:5]))

#  5ê°œ ìƒ˜í”Œì— ëŒ€í•œ ì˜ˆì¸¡ í™•ë¥  ?
print("\n Percentage of 5 test_scaled") 
proba = lr2.predict_proba(test_scaled[:5])   
print(np.round(proba, decimals = 3))
```

ì—¬ê¸°ì„œ CëŠ”  $1/alpha$ ê°’ì´ë‹¤. ë¡œì§€ìŠ¤í‹± íšŒê·€ëŠ” ë¦¿ì§€ íšŒê·€ì™€ ê°™ì´ ê³„ìˆ˜ì˜ ì œê³±ì„ ê·œì œí•˜ê³ , ë¦¿ì§€ íšŒê·€ì— alpha ë§¤ê°œë³€ìˆ˜ê°€ ìˆë“¯ì´ ë¡œì§€ìŠ¤í‹± íšŒê·€ì—ì„œë„ ë¹„ìŠ·í•œ ì—­í• ì„ í•˜ëŠ” (í•˜ì§€ë§Œ alphaì˜ ì—­ìˆ˜ì¸) C ë§¤ê°œë³€ìˆ˜ê°€ ì¡´ì¬í•œë‹¤.

![Untitled](%E1%84%85%E1%85%A9%E1%84%8C%E1%85%B5%E1%84%89%E1%85%B3%E1%84%90%E1%85%B5%E1%86%A8%20%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%2016265685b00c476aa50007c3e939fc9d/Untitled%206.png)

ì´ë²ˆì—” decisionsê°’ì„ ì´ìš©í•´ ì†Œí”„íŠ¸ë§¥ìŠ¤ í•¨ìˆ˜ì— ë„£ì–´ ë‚˜ì˜¨ ê°’ìœ¼ë¡œ í™•ë¥ ì„ êµ¬í•´ë³´ì.

```python
decisions2 = lr2.decision_function(test_scaled[:5])
print("\nDecisions2 (Z) of 7 Species : ")
print(np.round(decisions2, decimals = 2))

# zê°’ ê²°ê³¼ë¥¼ softmaxì— ì˜ë¢°
from scipy.special import softmax
print("\n PREDICT OF 5 decisions2 using Softmax")
proba2 = softmax(decisions2, axis = 1) # axis=1ì´ë©´ ê° ìƒ˜í”Œì— ëŒ€í•œ ì†Œí”„íŠ¸ë§¥ìŠ¤ë¥¼ ê³„ì‚°í•¨.
print(np.round(proba2, decimals = 3))
```

![Untitled](%E1%84%85%E1%85%A9%E1%84%8C%E1%85%B5%E1%84%89%E1%85%B3%E1%84%90%E1%85%B5%E1%86%A8%20%E1%84%92%E1%85%AC%E1%84%80%E1%85%B1%2016265685b00c476aa50007c3e939fc9d/Untitled%207.png)

ìœ„ì˜ predict_proba() ë©”ì„œë“œë¥¼ í†µí•œ ê²°ê³¼ì™€ ë™ì¼í•œë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.